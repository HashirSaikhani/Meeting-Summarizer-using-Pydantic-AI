Feature: Knowledge base ingestion mechanism (initial and updates)
==================================================================

The knowledge base ingestion mechanism supports both initial setup and ongoing updates. Initially, when a new client onboards, a pipeline is established to ingest their knowledge base, which can be in various formats including Google Docs, Word, PDF, Excel, plain text, and meeting transcripts. The system includes a mechanism to upload multiple documents, with the backend responsible for processing and converting them to a standardized format. Additionally, chat data can be ingested by actively listening to event chats or polling WhatsApp APIs and backups, with an option to extract up to six months of past messages.

For updates and dynamic information, the system differentiates between static and dynamic content. While initial information remains static, dynamic content (expected to be around 25-40 cases) is fetched from the database. An LLM automatically handles dynamic information to fetch answers to recurring questions. Clients can manually update dynamic information through a dashboard interface, where they fill out a form, push a button to convert the data into embeds, and update existing ones. A function-calling mechanism is also in place to fetch dynamic data from the DB for facts that change over time. The system can also scrape and fetch the latest rates and schedules, such as exam schedules.

New knowledge or facts undergo a configurable review cycle (1-2 weeks). Raw information is retained for two weeks and reprocessed after four weeks to update text while preserving context, ensuring new ingestion does not overlap old data. The system is designed to identify and dynamically handle similar or duplicate information by checking similarity scores among facts. Scheduled updates occur in panels, requiring user input for dynamic adjustments rather than being fully automatic. Stack information is stored and auto-updated, and users can configure review levels (automatic or initial) with new information appearing on the dashboard.

The system supports various media types, including text, audio, and images. While videos are initially ignored, their audio can be extracted and transcribed into text for processing. Rate limits and size constraints are imposed for different message types (audio length, text length, up to 200 image files) and overall bot interactions (e.g., 60 messages per hour) to prevent overloading. The system discards unnecessary data such as 3D content or excessively long inputs. The architecture is single-tenant but can manage multiple services or knowledge bases per tenant with unique deployments, ensuring transparent handling of data and service assignments.